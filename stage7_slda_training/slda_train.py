# -*- coding: utf-8 -*-
"""Slda_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ztFIUU_-gCupYNBDavcFhrtX1vj549f0
"""

import os
print(os.getcwd())

from google.colab import drive
drive.mount('/mnt/gdrive')



# =========================
# SLDA: Sequential Legal Domain Adaptation (A100-optimized)
# =========================
!pip install -q transformers datasets evaluate accelerate

import os, random, inspect
import pandas as pd
import numpy as np
from typing import Dict
import torch
from torch.utils.data import Dataset
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    Trainer, TrainingArguments, DataCollatorWithPadding
)
import evaluate

# -------------------------
# Speed knobs for A100
# -------------------------
torch.backends.cuda.matmul.allow_tf32 = True
torch.set_float32_matmul_precision("high")
USE_BF16 = torch.cuda.is_available()  # A100 supports bf16 very well

# -------------------------
# Config
# -------------------------
BASE_CKPT = "/mnt/gdrive/MyDrive/legalbert-snli-finetuned"

ARTICLE_FILES: Dict[str, str] = {
    "Article 2": "/mnt/gdrive/MyDrive/NLI_Results/article2_nli_semantic_pairs_unique_labeled.csv",
    "Article 3": "/mnt/gdrive/MyDrive/NLI_Results/article3_nli_semantic_pairs_labeled.csv",
    "Article 7": "/mnt/gdrive/MyDrive/NLI_Results/article7_nli_semantic_pairs_labeled.csv",
    "Article 8": "/mnt/gdrive/MyDrive/NLI_Results/article8_nli_semantic_pairs_labeled.csv",
}

OUT_DIR = "/mnt/gdrive/MyDrive/SLDA_checkpoints"
os.makedirs(OUT_DIR, exist_ok=True)

SEED = 42
VAL_FRAC = 0.1

# epochs & lr (conservative to preserve prior knowledge)
STAGE1_EPOCHS = 3
STAGE2_EPOCHS = 3
LR_STAGE1 = 1e-5
LR_STAGE2 = 1e-5

# Bigger batches for A100 (lower if OOM)
BATCH_TRAIN = 32
BATCH_EVAL  = 64
MAX_LEN = 256

ARTICLE_ORDER = ["Article 2", "Article 3", "Article 7", "Article 8"]

random.seed(SEED); np.random.seed(SEED)
device = "cuda" if torch.cuda.is_available() else "cpu"

# -------------------------
# Helpers
# -------------------------
def read_df(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    need = {"premise", "hypothesis", "label"}
    miss = need - set(df.columns)
    if miss:
        raise ValueError(f"Missing columns in {path}: {miss}")
    return df.dropna(subset=["premise", "hypothesis", "label"]).reset_index(drop=True)

def normalize_label(x: str) -> str:
    y = str(x).strip().lower()
    if y.startswith("entail"): return "entailment"
    if y.startswith("contra"): return "contradiction"
    return "neutral"

class PairDS(Dataset):
    def __init__(self, df, tokenizer, label2id, max_len=256):
        self.prem = df["premise"].astype(str).tolist()
        self.hyp  = df["hypothesis"].astype(str).tolist()
        self.y    = [label2id[normalize_label(v)] for v in df["label"].tolist()]
        self.tok  = tokenizer
        self.max_len = max_len
    def __len__(self): return len(self.y)
    def __getitem__(self, i):
        enc = self.tok(self.prem[i], self.hyp[i], truncation=True, max_length=self.max_len)
        enc["labels"] = self.y[i]
        return {k: torch.tensor(v) for k, v in enc.items()}

acc = evaluate.load("accuracy")
f1m = evaluate.load("f1")
def make_metrics(id2label):
    def compute(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)
        out = {
            "accuracy": acc.compute(predictions=preds, references=labels)["accuracy"],
            "f1_macro": f1m.compute(predictions=preds, references=labels, average="macro")["f1"],
        }
        # Per-class F1 (binary one-vs-rest)
        for i, name in sorted(id2label.items()):
            out[f"f1_{name}"] = f1m.compute(
                predictions=(preds==i).astype(int),
                references=(labels==i).astype(int),
                average="binary"
            )["f1"]
        return out
    return compute

# --- v4/v5 compatible Trainer subclass ---
class WeightedTrainer(Trainer):
    def __init__(self, *args, class_weights=None, **kw):
        super().__init__(*args, **kw)
        self.class_weights = None if class_weights is None else torch.tensor(class_weights, dtype=torch.float)
    # accept extra kwargs like num_items_in_batch (v5)
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits  = outputs.logits
        loss_fct = torch.nn.CrossEntropyLoss(
            weight=None if self.class_weights is None else self.class_weights.to(logits.device)
        )
        loss = loss_fct(logits, labels)
        return (loss, outputs) if return_outputs else loss

def class_weights_from_df(df, label2id):
    labs = [normalize_label(v) for v in df["label"].tolist()]
    unknown = sorted(set(labs) - set(label2id.keys()))
    if unknown:
        raise ValueError(f"Found unknown labels {unknown}. "
                         f"Seen={sorted(set(labs))}, expected keys={sorted(label2id.keys())}")
    ids = [label2id[x] for x in labs]
    counts = np.bincount(ids, minlength=len(label2id))
    inv = 1.0 / np.clip(counts, 1, None)
    weights = inv * (len(inv) / inv.sum())
    return weights, counts

from transformers import TrainingArguments
def fast_args(out_dir, epochs, lr):
    # Build kwargs that work across v4/v5 of transformers
    kwargs = dict(
        output_dir=out_dir,
        num_train_epochs=epochs,
        learning_rate=lr,
        per_device_train_batch_size=BATCH_TRAIN,
        per_device_eval_batch_size=BATCH_EVAL,
        save_strategy="epoch",
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="f1_macro",
        greater_is_better=True,
        # speed
        bf16=USE_BF16,
        fp16=False,
        optim="adamw_torch_fused",
        warmup_ratio=0.06,
        weight_decay=0.01,
        dataloader_num_workers=4,
        logging_steps=200,
        report_to="none",
        seed=SEED,
        torch_compile=True,
        torch_compile_backend="inductor",
    )
    sig = inspect.signature(TrainingArguments)
    if "evaluation_strategy" in sig.parameters:
        kwargs["evaluation_strategy"] = "epoch"
    elif "eval_strategy" in sig.parameters:
        kwargs["eval_strategy"] = "epoch"
    # prune unsupported keys
    allowed = set(sig.parameters.keys())
    kwargs = {k: v for k, v in kwargs.items() if k in allowed}
    return TrainingArguments(**kwargs)

# Helper to pass tokenizer/processing_class across versions
def build_trainer_kwargs(base_kwargs):
    sig = inspect.signature(Trainer.__init__)
    kw = dict(base_kwargs)
    if "processing_class" in sig.parameters:
        kw["processing_class"] = kw.pop("tokenizer", None)
    elif "tokenizer" in sig.parameters:
        # keep tokenizer
        pass
    else:
        kw.pop("tokenizer", None)
    allowed = set(sig.parameters.keys()) - {"self"}
    return {k: v for k, v in kw.items() if k in allowed}

# -------------------------
# Load model & tokenizer + fix label maps
# -------------------------
model = AutoModelForSequenceClassification.from_pretrained(BASE_CKPT)
tokenizer = AutoTokenizer.from_pretrained(BASE_CKPT, use_fast=True)
collator = DataCollatorWithPadding(tokenizer)

CANONICAL = {"entailment": 0, "contradiction": 1, "neutral": 2}
cfg = model.config
have = {k.lower(): v for k, v in (getattr(cfg, "label2id", {}) or {}).items()}
need_head_resize = (getattr(cfg, "num_labels", None) != 3)
if need_head_resize:
    model = AutoModelForSequenceClassification.from_pretrained(BASE_CKPT, num_labels=3)

# Force canonical mapping to avoid KeyErrors
model.config.label2id = CANONICAL
model.config.id2label = {v: k for k, v in CANONICAL.items()}
label2id = model.config.label2id
id2label = model.config.id2label

compute_metrics = make_metrics(id2label)

# =========================
# Stage 1: Combined CPRA adaptation
# =========================
dfs = [read_df(p) for p in ARTICLE_FILES.values()]
df_all = pd.concat(dfs, ignore_index=True)
df_all["label"] = df_all["label"].apply(normalize_label)
df_all = df_all.sample(frac=1.0, random_state=SEED).reset_index(drop=True)

cut = int((1.0-VAL_FRAC)*len(df_all))
df_tr1, df_val1 = df_all.iloc[:cut], df_all.iloc[cut:]

cw1, c1 = class_weights_from_df(df_tr1, label2id)
print("Stage-1 class counts:", dict(zip([id2label[i] for i in range(len(c1))], c1)))
print("Stage-1 weights:", np.round(cw1, 3))

train_ds1 = PairDS(df_tr1, tokenizer, label2id, MAX_LEN)
val_ds1   = PairDS(df_val1, tokenizer, label2id, MAX_LEN)

out_stage1 = os.path.join(OUT_DIR, "stage1_combined")
args1 = fast_args(out_stage1, STAGE1_EPOCHS, LR_STAGE1)

base_kwargs1 = dict(
    model=model,
    args=args1,
    train_dataset=train_ds1,
    eval_dataset=val_ds1,
    data_collator=collator,
    compute_metrics=compute_metrics,
    class_weights=cw1,
    tokenizer=tokenizer,   # will be mapped to processing_class on v5
)
trainer1 = WeightedTrainer(**build_trainer_kwargs(base_kwargs1))
trainer1.train()
trainer1.save_model(out_stage1)
tokenizer.save_pretrained(out_stage1)

stage1_model_path = out_stage1
print("Stage-1 model saved at:", stage1_model_path)

# =========================
# Stage 2: Article-specific specialization
# =========================
def eval_on_all(model):
    from sklearn.metrics import f1_score
    snap = {}
    for art, path in ARTICLE_FILES.items():
        df = read_df(path)
        df["label"] = df["label"].apply(normalize_label)
        df = df.sample(frac=1.0, random_state=SEED)
        cut = int((1.0-VAL_FRAC)*len(df))
        df_va = df.iloc[cut:]
        ds = PairDS(df_va, tokenizer, label2id, MAX_LEN)

        model.eval()
        preds, gold = [], []
        for i in range(len(ds)):
            item = {k: v.unsqueeze(0).to(device) for k, v in ds[i].items()}
            y = item.pop("labels").item()
            with torch.no_grad():
                logits = model(**item).logits
            preds.append(int(torch.argmax(logits, -1).cpu().item()))
            gold.append(y)
        preds, gold = np.array(preds), np.array(gold)
        acc_val = (preds == gold).mean().item()
        f1_val  = f1_score(gold, preds, average="macro")
        snap[art] = {"acc": acc_val, "f1_macro": f1_val}
    return snap

# Evaluate Stage-1 snapshot
m_stage1 = AutoModelForSequenceClassification.from_pretrained(stage1_model_path).to(device)
stage1_snap = eval_on_all(m_stage1)
print("Stage-1 snapshot:", stage1_snap)

# Train & evaluate specialized models
all_results = []
for art in ARTICLE_ORDER:
    print(f"\n=== Stage-2: Specializing for {art} ===")
    df = read_df(ARTICLE_FILES[art])
    df["label"] = df["label"].apply(normalize_label)
    df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)
    cut = int((1.0-VAL_FRAC)*len(df))
    df_tr2, df_va2 = df.iloc[:cut], df.iloc[cut:]

    cw2, c2 = class_weights_from_df(df_tr2, label2id)
    print("Stage-2 counts:", dict(zip([id2label[i] for i in range(len(c2))], c2)))
    print("Stage-2 weights:", np.round(cw2, 3))

    ds_tr2 = PairDS(df_tr2, tokenizer, label2id, MAX_LEN)
    ds_va2 = PairDS(df_va2, tokenizer, label2id, MAX_LEN)

    out_art = os.path.join(OUT_DIR, f"stage2_{art.replace(' ','_')}")
    args2 = fast_args(out_art, STAGE2_EPOCHS, LR_STAGE2)

    m_art = AutoModelForSequenceClassification.from_pretrained(stage1_model_path).to(device)

    base_kwargs2 = dict(
        model=m_art,
        args=args2,
        train_dataset=ds_tr2,
        eval_dataset=ds_va2,
        data_collator=collator,
        compute_metrics=compute_metrics,
        class_weights=cw2,
        tokenizer=tokenizer,
    )
    trainer2 = WeightedTrainer(**build_trainer_kwargs(base_kwargs2))
    trainer2.train()
    trainer2.save_model(out_art)
    tokenizer.save_pretrained(out_art)

    snap = eval_on_all(m_art)
    for ev_on, m in snap.items():
        all_results.append({
            "stage": f"Stage2_{art}",
            "article_model": art,
            "eval_on": ev_on,
            "acc": m["acc"],
            "f1_macro": m["f1_macro"],
        })

# Save results
res_df = pd.DataFrame(all_results)
res_path = os.path.join(OUT_DIR, "slda_results.csv")
res_df.to_csv(res_path, index=False)
print("Saved metrics to:", res_path)
print("Done. Checkpoints in:", OUT_DIR)